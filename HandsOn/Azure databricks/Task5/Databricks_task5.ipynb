{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1411128e-5ae2-4675-8117-0e4526d5dcfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Assignment 17-09-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5eafaeb-dabf-4d9c-b68f-c088d0b81a3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/employee.csv\", \"dbfs:/FileStore/streaming/input/employee.csv\") \n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/products.json\", \"dbfs:/FileStore/streaming/input/products.json\")\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/new_employee.csv\", \"dbfs:/FileStore/streaming/input/new_employee.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe769c6e-4932-42b5-88b5-f320d4f2f500",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "502e4883-91b9-47e9-9719-38dc7141bbc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_file = \"dbfs:/FileStore/streaming/input/employee.csv\"\n",
    "json_file = \"dbfs:/FileStore/streaming/input/products.json\"\n",
    "\n",
    "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file)\n",
    "df_json = spark.read.json(json_file)\n",
    "\n",
    "# 1. Create Delta Table from DataFrame\n",
    "df_csv.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/employees_df\")\n",
    "\n",
    "# 2. Use SQL to create Delta Table\n",
    "df_csv.createOrReplaceTempView(\"employees_view\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS employees_sql\n",
    "    USING delta\n",
    "    AS SELECT * FROM employees_view\n",
    "\"\"\")\n",
    "\n",
    "# 3. Convert CSV and JSON to Delta format\n",
    "df_csv.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/employees_csv\")\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ProductID\", StringType(), True),\n",
    "    StructField(\"ProductName\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"Price\", IntegerType(), True)\n",
    "])\n",
    "df_json = spark.read.schema(schema).json(json_file)\n",
    "\n",
    "df_json.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/products_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "837d7f35-37cb-4a1b-b0f6-aa2538f2e81c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2efb0862-d165-4955-8a41-4da834e8934e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_employee_csv_path =\"dbfs:/FileStore/streaming/input/new_employee.csv\"\n",
    "new_employee_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(new_employee_csv_path)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "new_employee_df = new_employee_df.withColumn(\"EmployeeID\", col(\"EmployeeID\").cast(\"int\")) \\\n",
    "                                 .withColumn(\"Salary\", col(\"Salary\").cast(\"int\"))\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"/delta/employees_csv\")\n",
    "\n",
    "delta_table.alias(\"old\").merge(\n",
    "    new_employee_df.alias(\"new\"),\n",
    "    \"old.EmployeeID = new.EmployeeID\"\n",
    ").whenMatchedUpdate(set = {\n",
    "    \"EmployeeName\": \"new.EmployeeName\",\n",
    "    \"Department\": \"new.Department\",\n",
    "    \"JoiningDate\": \"new.JoiningDate\",\n",
    "    \"Salary\": \"new.Salary\"  \n",
    "}).whenNotMatchedInsertAll().execute() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0554053d-ca62-42e8-944e-5fd21b2369bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c14b23-2246-4a29-bf4f-72b8d3ad1657",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|          userId|            userName|operation| operationParameters| job|         notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|      3|2024-09-17 04:08:51|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|          2|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      2|2024-09-17 04:08:48|2929584751483774|azuser2141_mml.lo...|    MERGE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|          1|WriteSerializable|        false|{numTargetRowsCop...|        NULL|Databricks-Runtim...|\n",
      "|      1|2024-09-17 04:05:25|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{418182220691607}|0912-053226-p5usobai|          0|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|      0|2024-09-17 04:02:11|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> ErrorIfE...|NULL|{418182220691607}|0912-053226-p5usobai|       NULL|WriteSerializable|         true|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n",
      "+----------+------------+-----------+-----------+------+\n",
      "|EmployeeID|EmployeeName| Department|JoiningDate|Salary|\n",
      "+----------+------------+-----------+-----------+------+\n",
      "|       101|        John|         HR| 2023-01-10| 50000|\n",
      "|       102|       Alice|    Finance| 2023-02-15| 70000|\n",
      "|       103|        Mark|Engineering| 2023-03-20| 85000|\n",
      "|       104|        Emma|      Sales| 2023-04-01| 55000|\n",
      "|       105|        Liam|  Marketing| 2023-05-12| 60000|\n",
      "+----------+------------+-----------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check transaction history\n",
    "spark.sql(\"DESCRIBE HISTORY '/delta/employees_csv'\").show()\n",
    "\n",
    "# Perform time travel\n",
    "df_time_travel = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/delta/employees_csv\")\n",
    "df_time_travel.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ecf0efa-ec61-4922-8782-dee8999bf823",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eadf1984-72b1-4468-9c6c-f3690d0c427f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numClusteringTasksPlanned:int,numCompactionTasksPlanned:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numIntermediateNodesCompacted:bigint,totalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"OPTIMIZE '/delta/employees_csv' ZORDER BY Department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6256caf4-d3a1-402f-8315-3b2f10b4fea1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d77419d3-1d3c-4c96-a045-c60fba439053",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+-----------+------+\n",
      "|EmployeeID|EmployeeName| Department|JoiningDate|Salary|\n",
      "+----------+------------+-----------+-----------+------+\n",
      "|       101|        John|         HR| 2023-01-10| 50000|\n",
      "|       102|       Alice|    Finance| 2023-02-15| 70000|\n",
      "|       103|        Mark|Engineering| 2023-03-20| 85000|\n",
      "|       104|        Emma|      Sales| 2023-04-01| 55000|\n",
      "|       105|        Liam|  Marketing| 2023-05-12| 60000|\n",
      "+----------+------------+-----------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_travel = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/delta/employees_csv\")\n",
    "df_time_travel.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2a532c6-5229-4f0c-9b93-04e9d997cf77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ffb24e-fd64-4110-a4df-c00668f10f8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"VACUUM '/delta/employees_csv' RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8610dcf2-56d6-4de8-bb82-bcee2781a464",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Structured Streaming and Transformations on Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82cc6b9-1852-4869-ae7d-9e0f88af1e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/transactions.csv\", \"dbfs:/FileStore/streaming/input/transactions.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dad02041-cdd4-437e-b76b-a734561c8e94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84b499ad-e864-4f18-acbf-242dd5d01f87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "static_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/streaming/input/transactions.csv\")\n",
    "schema = static_df.schema\n",
    "\n",
    "streaming_df = spark.readStream.format(\"csv\").option(\"header\", \"true\").schema(schema).load(\"dbfs:/FileStore/streaming/input/\")\n",
    "\n",
    "query = streaming_df.writeStream.format(\"console\").start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac06126f-449d-4b28-9121-1b6e5d4a7bbe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de1d881-2085-4ef8-b693-890cd021c7d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Add a new column for the TotalAmount ( Quantity * Price ).\n",
    "#Filter records where the Quantity is greater than 1.\n",
    "transformed_df = streaming_df.withColumn(\"TotalAmount\", streaming_df[\"Quantity\"] * streaming_df[\"Price\"]).filter(streaming_df[\"Quantity\"] > 1)\n",
    "\n",
    "query = transformed_df.writeStream.format(\"memory\").queryName(\"transformed_stream\").start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4115e790-0651-4a23-854d-1b94b631fda1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a390981a-819d-44ab-a994-5dcf73f8bad6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "#Group the data by ProductID and calculate the total sales for each product\n",
    "aggregated_df = streaming_df.groupBy(\"ProductID\").agg(sum(col(\"Quantity\") * col(\"Price\")).alias(\"TotalSales\"))\n",
    "query = aggregated_df.writeStream.format(\"console\").outputMode(\"update\").start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44400491-7d18-4198-818f-dff585be6f79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "226ecde6-ae6c-4560-bb37-625145e05c23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = transformed_df.writeStream.format(\"parquet\").option(\"path\", \"/dbfs/FileStore/parquet\") \\\n",
    "                                   .option(\"checkpointLocation\", \"/dbfs/FileStore/checkpoint\") \\\n",
    "                                   .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49cab256-73c3-499d-9fc8-599ac299ff32",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62848a9b-e39d-49a1-95ee-756c0f573aed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "streaming_df = streaming_df.withColumn(\"TransactionDate\", to_timestamp(col(\"TransactionDate\")))\n",
    "\n",
    "watermarked_df = streaming_df.withWatermark(\"TransactionDate\", \"1 day\")\n",
    "\n",
    "watermarked_query = watermarked_df.writeStream.format(\"console\").start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68a3d79c-bfca-445b-8083-ce572cb8e9c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb8a6776-99c6-4d5c-b969-eba2d322f6ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Stream 1: Incoming transaction data (CSV)\n",
    "transactions_stream = spark.readStream.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"basePath\", \"dbfs:/FileStore/streaming/input/\") \\\n",
    "    .schema(\"TransactionID STRING, TransactionDate DATE, ProductID STRING, Quantity INT, Price DOUBLE\") \\\n",
    "    .load(\"dbfs:/FileStore/streaming/input/\")\n",
    "\n",
    "# Stream 2: Product information (JSON)\n",
    "products_stream = spark.readStream.format(\"json\") \\\n",
    "    .option(\"basePath\", \"dbfs:/FileStore/streaming/input/\") \\\n",
    "    .schema(\"ProductID STRING, ProductName STRING, Category STRING\") \\\n",
    "    .load(\"dbfs:/FileStore/streaming/input/\")\n",
    "\n",
    "# Join both streams on ProductID\n",
    "joined_stream = transactions_stream.join(products_stream, \"ProductID\")\n",
    "\n",
    "# Write the joined stream to the console to visualize results\n",
    "query = joined_stream.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2659cd45-c291-4a7a-83a1-3c6afa8d219a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3669b33-0c2a-48ce-9243-464bade5fabd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating a Complete ETL Pipeline using Delta Live Tables (DLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23600180-8a1c-45f4-b279-b4df33a1be55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/orders.csv\", \"dbfs:/FileStore/streaming/input/orders.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fb014ac-5acd-416e-b35a-466080f751fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c53f852-6186-4767-8730-d78eafb16ba8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "  <style>\n",
       "<style>\n",
       "      html {\n",
       "        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n",
       "        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n",
       "        Noto Color Emoji,FontAwesome;\n",
       "        font-size: 13;\n",
       "      }\n",
       "\n",
       "      .ansiout {\n",
       "        padding-bottom: 8px;\n",
       "      }\n",
       "\n",
       "      .createPipeline {\n",
       "        background-color: rgb(34, 114, 180);\n",
       "        color: white;\n",
       "        text-decoration: none;\n",
       "        padding: 4px 12px;\n",
       "        border-radius: 4px;\n",
       "        display: inline-block;\n",
       "      }\n",
       "\n",
       "      .createPipeline:hover {\n",
       "        background-color: #195487;\n",
       "      }\n",
       "\n",
       "      .tag {\n",
       "        border: none;\n",
       "        color: rgb(31, 39, 45);\n",
       "        padding: 2px 4px;\n",
       "        font-weight: 600;\n",
       "        background-color: rgba(93, 114, 131, 0.08);\n",
       "        border-radius: 4px;\n",
       "        margin-right: 0;\n",
       "        display: inline-block;\n",
       "        cursor: default;\n",
       "      }\n",
       "\n",
       "      table {\n",
       "        border-collapse: collapse;\n",
       "        font-size: 13px;\n",
       "      }\n",
       "\n",
       "      th {\n",
       "        text-align: left;\n",
       "        background-color: #F2F5F7;\n",
       "        padding-left: 8px;\n",
       "        padding-right: 8px;\n",
       "      }\n",
       "\n",
       "      tr {\n",
       "        border-bottom: solid;\n",
       "        border-bottom-color: #CDDAE5;\n",
       "        border-bottom-width: 1px;\n",
       "      }\n",
       "\n",
       "      td {\n",
       "        padding-left: 8px;\n",
       "        padding-right: 8px;\n",
       "      }\n",
       "\n",
       "      .dlt-label {\n",
       "        font-weight: bold;\n",
       "      }\n",
       "\n",
       "      ul {\n",
       "        list-style: circle;\n",
       "        padding-inline-start: 12px;\n",
       "      }\n",
       "\n",
       "      li {\n",
       "        padding-bottom: 4px;\n",
       "      }\n",
       "</style></style>\n",
       "  \n",
       "<div class=\"ansiout\">\n",
       "<span class='tag'>incremental_orders</span> is defined as a\n",
       "<span class=\"dlt-label\">Delta Live Tables</span> dataset\n",
       " with schema: \n",
       "</div>\n",
       "\n",
       "  \n",
       "<div class=\"ansiout\">\n",
       "   <table>\n",
       "     <tbody>\n",
       "       <tr>\n",
       "         <th>Name</th>\n",
       "         <th>Type</th>\n",
       "       </tr>\n",
       "       \n",
       "<tr>\n",
       "   <td>OrderID</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>OrderDate</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>CustomerID</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>Product</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>Quantity</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>Price</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>TotalAmount</td>\n",
       "   <td>double</td>\n",
       "</tr>\n",
       "     </tbody>\n",
       "   </table>\n",
       "</div>\n",
       "\n",
       "  <div class =\"ansiout\">\n",
       "    To populate your table you must either:\n",
       "    <ul>\n",
       "      <li>\n",
       "        Run an existing pipeline using the\n",
       "        <span class=\"dlt-label\">Delta Live Tables</span> menu\n",
       "      </li>\n",
       "      <li>\n",
       "        Create a new pipeline: <a class='createPipeline' href=\"?o=419276616380425#joblist/pipelines/create?initialSource=%2FUsers%2Fazuser2141_mml.local%40techademy.com%2FSep%2017&redirectNotebookId=418182220691607\">Create Pipeline</a>\n",
       "      </li>\n",
       "    </ul>\n",
       "  <div>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "@dlt.table\n",
    "def transformed_orders():\n",
    "    # Read CSV source\n",
    "    df = spark.read.csv(\"dbfs:/FileStore/streaming/input/orders.csv\", header=True)\n",
    "    \n",
    "    # Transform data\n",
    "    df_transformed = df.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"Price\")) \\\n",
    "                       .filter(col(\"Quantity\") > 1)\n",
    "    \n",
    "    return df_transformed\n",
    "\n",
    "@dlt.table\n",
    "def incremental_orders():\n",
    "    return dlt.read_stream(\"transformed_orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "184825cd-a2b4-4524-8008-6543c70208c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6bea20f-7b6e-42d0-89a8-b1f0c6b7d9cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df_orders = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"dbfs:/FileStore/streaming/input/orders.csv\")\n",
    "\n",
    "df_orders.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/orders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77eb71e2-e10e-493c-9cb2-9904102f7c74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "  <style>\n",
       "<style>\n",
       "      html {\n",
       "        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n",
       "        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n",
       "        Noto Color Emoji,FontAwesome;\n",
       "        font-size: 13;\n",
       "      }\n",
       "\n",
       "      .ansiout {\n",
       "        padding-bottom: 8px;\n",
       "      }\n",
       "\n",
       "      .createPipeline {\n",
       "        background-color: rgb(34, 114, 180);\n",
       "        color: white;\n",
       "        text-decoration: none;\n",
       "        padding: 4px 12px;\n",
       "        border-radius: 4px;\n",
       "        display: inline-block;\n",
       "      }\n",
       "\n",
       "      .createPipeline:hover {\n",
       "        background-color: #195487;\n",
       "      }\n",
       "\n",
       "      .tag {\n",
       "        border: none;\n",
       "        color: rgb(31, 39, 45);\n",
       "        padding: 2px 4px;\n",
       "        font-weight: 600;\n",
       "        background-color: rgba(93, 114, 131, 0.08);\n",
       "        border-radius: 4px;\n",
       "        margin-right: 0;\n",
       "        display: inline-block;\n",
       "        cursor: default;\n",
       "      }\n",
       "\n",
       "      table {\n",
       "        border-collapse: collapse;\n",
       "        font-size: 13px;\n",
       "      }\n",
       "\n",
       "      th {\n",
       "        text-align: left;\n",
       "        background-color: #F2F5F7;\n",
       "        padding-left: 8px;\n",
       "        padding-right: 8px;\n",
       "      }\n",
       "\n",
       "      tr {\n",
       "        border-bottom: solid;\n",
       "        border-bottom-color: #CDDAE5;\n",
       "        border-bottom-width: 1px;\n",
       "      }\n",
       "\n",
       "      td {\n",
       "        padding-left: 8px;\n",
       "        padding-right: 8px;\n",
       "      }\n",
       "\n",
       "      .dlt-label {\n",
       "        font-weight: bold;\n",
       "      }\n",
       "\n",
       "      ul {\n",
       "        list-style: circle;\n",
       "        padding-inline-start: 12px;\n",
       "      }\n",
       "\n",
       "      li {\n",
       "        padding-bottom: 4px;\n",
       "      }\n",
       "</style></style>\n",
       "  \n",
       "<div class=\"ansiout\">\n",
       "<span class='tag'>transformed_orders</span> is defined as a\n",
       "<span class=\"dlt-label\">Delta Live Tables</span> dataset\n",
       " with schema: \n",
       "</div>\n",
       "\n",
       "  \n",
       "<div class=\"ansiout\">\n",
       "   <table>\n",
       "     <tbody>\n",
       "       <tr>\n",
       "         <th>Name</th>\n",
       "         <th>Type</th>\n",
       "       </tr>\n",
       "       \n",
       "<tr>\n",
       "   <td>OrderID</td>\n",
       "   <td>int</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>OrderDate</td>\n",
       "   <td>date</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>CustomerID</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>Product</td>\n",
       "   <td>string</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>Quantity</td>\n",
       "   <td>int</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>Price</td>\n",
       "   <td>int</td>\n",
       "</tr>\n",
       "\n",
       "<tr>\n",
       "   <td>TotalAmount</td>\n",
       "   <td>int</td>\n",
       "</tr>\n",
       "     </tbody>\n",
       "   </table>\n",
       "</div>\n",
       "\n",
       "  <div class =\"ansiout\">\n",
       "    To populate your table you must either:\n",
       "    <ul>\n",
       "      <li>\n",
       "        Run an existing pipeline using the\n",
       "        <span class=\"dlt-label\">Delta Live Tables</span> menu\n",
       "      </li>\n",
       "      <li>\n",
       "        Create a new pipeline: <a class='createPipeline' href=\"?o=419276616380425#joblist/pipelines/create?initialSource=%2FUsers%2Fazuser2141_mml.local%40techademy.com%2FSep%2017&redirectNotebookId=418182220691607\">Create Pipeline</a>\n",
       "      </li>\n",
       "    </ul>\n",
       "  <div>\n",
       "</html>\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n<html>\n  <style>\n<style>\n      html {\n        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,\n        Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,\n        Noto Color Emoji,FontAwesome;\n        font-size: 13;\n      }\n\n      .ansiout {\n        padding-bottom: 8px;\n      }\n\n      .createPipeline {\n        background-color: rgb(34, 114, 180);\n        color: white;\n        text-decoration: none;\n        padding: 4px 12px;\n        border-radius: 4px;\n        display: inline-block;\n      }\n\n      .createPipeline:hover {\n        background-color: #195487;\n      }\n\n      .tag {\n        border: none;\n        color: rgb(31, 39, 45);\n        padding: 2px 4px;\n        font-weight: 600;\n        background-color: rgba(93, 114, 131, 0.08);\n        border-radius: 4px;\n        margin-right: 0;\n        display: inline-block;\n        cursor: default;\n      }\n\n      table {\n        border-collapse: collapse;\n        font-size: 13px;\n      }\n\n      th {\n        text-align: left;\n        background-color: #F2F5F7;\n        padding-left: 8px;\n        padding-right: 8px;\n      }\n\n      tr {\n        border-bottom: solid;\n        border-bottom-color: #CDDAE5;\n        border-bottom-width: 1px;\n      }\n\n      td {\n        padding-left: 8px;\n        padding-right: 8px;\n      }\n\n      .dlt-label {\n        font-weight: bold;\n      }\n\n      ul {\n        list-style: circle;\n        padding-inline-start: 12px;\n      }\n\n      li {\n        padding-bottom: 4px;\n      }\n</style></style>\n  \n<div class=\"ansiout\">\n<span class='tag'>transformed_orders</span> is defined as a\n<span class=\"dlt-label\">Delta Live Tables</span> dataset\n with schema: \n</div>\n\n  \n<div class=\"ansiout\">\n   <table>\n     <tbody>\n       <tr>\n         <th>Name</th>\n         <th>Type</th>\n       </tr>\n       \n<tr>\n   <td>OrderID</td>\n   <td>int</td>\n</tr>\n\n<tr>\n   <td>OrderDate</td>\n   <td>date</td>\n</tr>\n\n<tr>\n   <td>CustomerID</td>\n   <td>string</td>\n</tr>\n\n<tr>\n   <td>Product</td>\n   <td>string</td>\n</tr>\n\n<tr>\n   <td>Quantity</td>\n   <td>int</td>\n</tr>\n\n<tr>\n   <td>Price</td>\n   <td>int</td>\n</tr>\n\n<tr>\n   <td>TotalAmount</td>\n   <td>int</td>\n</tr>\n     </tbody>\n   </table>\n</div>\n\n  <div class =\"ansiout\">\n    To populate your table you must either:\n    <ul>\n      <li>\n        Run an existing pipeline using the\n        <span class=\"dlt-label\">Delta Live Tables</span> menu\n      </li>\n      <li>\n        Create a new pipeline: <a class='createPipeline' href=\"?o=419276616380425#joblist/pipelines/create?initialSource=%2FUsers%2Fazuser2141_mml.local%40techademy.com%2FSep%2017&redirectNotebookId=418182220691607\">Create Pipeline</a>\n      </li>\n    </ul>\n  <div>\n</html>\n",
       "datasetInfos": [],
       "metadata": {
        "dataframeName": null
       },
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE LIVE TABLE transformed_orders AS\n",
    "SELECT *, Quantity * Price AS TotalAmount\n",
    "FROM delta.`/delta/orders`\n",
    "WHERE Quantity > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fee46da-b3af-4cb7-90eb-7324fde0e1f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5bdc65f-6b9b-409c-9443-9a4a237152f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1. Read the Data from the Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da42e36d-2ae1-49dd-a295-d56c0144594b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-------+--------+-----+\n",
      "|OrderID| OrderDate|CustomerID|Product|Quantity|Price|\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "|    101|2024-01-01|      C001| Laptop|       2| 1000|\n",
      "|    102|2024-01-02|      C002|  Phone|       1|  500|\n",
      "|    103|2024-01-03|      C003| Tablet|       3|  300|\n",
      "|    104|2024-01-04|      C004|Monitor|       1|  150|\n",
      "|    105|2024-01-05|      C005|  Mouse|       5|   20|\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the Delta table in PySpark\n",
    "df = spark.read.format(\"delta\").load(\"/delta/orders\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ebcbf1-09a1-4f75-856c-27a45b5db1ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>OrderID</th><th>OrderDate</th><th>CustomerID</th><th>Product</th><th>Quantity</th><th>Price</th></tr></thead><tbody><tr><td>101</td><td>2024-01-01</td><td>C001</td><td>Laptop</td><td>2</td><td>1000</td></tr><tr><td>102</td><td>2024-01-02</td><td>C002</td><td>Phone</td><td>1</td><td>500</td></tr><tr><td>103</td><td>2024-01-03</td><td>C003</td><td>Tablet</td><td>3</td><td>300</td></tr><tr><td>104</td><td>2024-01-04</td><td>C004</td><td>Monitor</td><td>1</td><td>150</td></tr><tr><td>105</td><td>2024-01-05</td><td>C005</td><td>Mouse</td><td>5</td><td>20</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         101,
         "2024-01-01",
         "C001",
         "Laptop",
         2,
         1000
        ],
        [
         102,
         "2024-01-02",
         "C002",
         "Phone",
         1,
         500
        ],
        [
         103,
         "2024-01-03",
         "C003",
         "Tablet",
         3,
         300
        ],
        [
         104,
         "2024-01-04",
         "C004",
         "Monitor",
         1,
         150
        ],
        [
         105,
         "2024-01-05",
         "C005",
         "Mouse",
         5,
         20
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 71
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "OrderID",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "OrderDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "CustomerID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Product",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Quantity",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Price",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Reading the Delta table using SQL\n",
    "SELECT * FROM delta.`/delta/orders`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "734eb089-92c0-4733-a778-7e5c6d1517cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2. Update the Price of a Product (e.g., increase Laptop price by 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2935f4a7-5b13-477b-b1f6-8d47ac90d263",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Load the Delta table\n",
    "delta_table = DeltaTable.forPath(spark, \"/delta/orders\")\n",
    "\n",
    "# Update the Price of 'Laptop' by increasing it by 10%\n",
    "delta_table.update(\n",
    "    condition = expr(\"Product = 'Laptop'\"),\n",
    "    set = { \"Price\": expr(\"Price * 1.1\") }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc909a0d-ae57-4dc0-8989-63a0c55f3f4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 76
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Update product price using SQL (increase Laptop price by 10%)\n",
    "UPDATE delta.`/delta/orders`\n",
    "SET Price = Price * 1.1\n",
    "WHERE Product = 'Laptop';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "647c0841-72ba-41a8-a002-d94d3d349540",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "3. Delete Rows where Quantity is Less Than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e06a7136-fd7f-42b0-b1a4-3a1e8c663932",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete rows where Quantity is less than 2\n",
    "delta_table.delete(condition = expr(\"Quantity < 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0147aed9-e555-4527-b549-f04503c29ee9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 80
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Delete rows where Quantity is less than 2\n",
    "DELETE FROM delta.`/delta/orders`\n",
    "WHERE Quantity < 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9195dd06-f33b-4cea-b8af-8a570dc93a1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4. Insert a New Record into the Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "459741e8-1fd7-429f-a85d-938ce5dfd996",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n",
    "\n",
    "# Insert a new record into the Delta table\n",
    "new_data = [(106, 'C006', 'Keyboard', 2, 50)]\n",
    "columns = [\"OrderID\", \"CustomerID\", \"Product\", \"Quantity\", \"Price\"]\n",
    "\n",
    "# Define the schema of the Delta table\n",
    "schema = StructType([\n",
    "    StructField(\"OrderID\", IntegerType(), nullable=False),\n",
    "    StructField(\"CustomerID\", StringType(), nullable=False),\n",
    "    StructField(\"Product\", StringType(), nullable=False),\n",
    "    StructField(\"Quantity\", IntegerType(), nullable=False),\n",
    "    StructField(\"Price\", IntegerType(), nullable=False)\n",
    "])\n",
    "\n",
    "# Create a DataFrame with new data and specified schema\n",
    "new_df = spark.createDataFrame(new_data, schema)\n",
    "\n",
    "# Append the new data to the Delta table\n",
    "new_df.write.format(\"delta\").mode(\"append\").save(\"/delta/orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3296f61b-5d9f-44e8-8359-420f5ed081dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 86
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Insert a new record using SQL\n",
    "INSERT INTO delta.`/delta/orders`\n",
    "VALUES (107, '2024-01-06', 'C006', 'Keyboard', 2, 50);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2bba3d9-7537-4b75-b068-a89fa2d1fba8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8969e647-9534-43b8-8931-7f3c232e7e14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# New data representing updated orders\n",
    "new_data = [(101, '2024-01-10', 'C001', 'Laptop', 2, 1200),  # Updated order for Laptop\n",
    "            (106, '2024-01-12', 'C006', 'Keyboard', 3, 50)]   # New order for Keyboard\n",
    "\n",
    "columns = [\"OrderID\", \"OrderDate\", \"CustomerID\", \"Product\", \"Quantity\", \"Price\"]\n",
    "\n",
    "# Create a DataFrame with the new data\n",
    "new_df = spark.createDataFrame(new_data, columns)\n",
    "\n",
    "# Merge the new data into the Delta table (SCD Type 2)\n",
    "delta_table.alias(\"old\").merge(\n",
    "    new_df.alias(\"new\"),\n",
    "    \"old.OrderID = new.OrderID\"\n",
    ").whenMatchedUpdate(set={\n",
    "    \"OrderDate\": \"new.OrderDate\",\n",
    "    \"CustomerID\": \"new.CustomerID\",\n",
    "    \"Product\": \"new.Product\",\n",
    "    \"Quantity\": \"new.Quantity\",\n",
    "    \"Price\": \"new.Price\"\n",
    "}).whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8464445-ce7b-4e9c-9bcf-ac771df62f25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ebe5ca-b247-4850-9659-f96d14e249bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|          userId|            userName|operation| operationParameters| job|         notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|     35|2024-09-17 05:04:39|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         34|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     34|2024-09-17 05:04:37|2929584751483774|azuser2141_mml.lo...|    MERGE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         33|WriteSerializable|        false|{numTargetRowsCop...|        NULL|Databricks-Runtim...|\n",
      "|     33|2024-09-17 04:58:42|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Append, ...|NULL|{418182220691607}|0912-053226-p5usobai|         32|WriteSerializable|         true|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|     32|2024-09-17 04:57:46|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Append, ...|NULL|{418182220691607}|0912-053226-p5usobai|         31|WriteSerializable|         true|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|     31|2024-09-17 04:56:02|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         30|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     30|2024-09-17 04:55:27|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         29|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     29|2024-09-17 04:55:01|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         28|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     28|2024-09-17 04:54:58|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         27|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     27|2024-09-17 04:54:36|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         26|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     26|2024-09-17 04:54:34|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         25|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     25|2024-09-17 04:53:11|2929584751483774|azuser2141_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{418182220691607}|0912-053226-p5usobai|         24|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|     24|2024-09-17 04:51:47|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         23|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     23|2024-09-17 04:51:46|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         22|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     22|2024-09-17 04:51:44|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         21|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     21|2024-09-17 04:50:56|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         20|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     20|2024-09-17 04:50:54|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         19|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     19|2024-09-17 04:50:53|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         18|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     18|2024-09-17 04:50:07|2929584751483774|azuser2141_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{418182220691607}|0912-053226-p5usobai|         17|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     17|2024-09-17 04:50:05|2929584751483774|azuser2141_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         16|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|     16|2024-09-17 04:50:04|2929584751483774|azuser2141_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{418182220691607}|0912-053226-p5usobai|         15|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "+-------+-------------------+----------------+--------------------+---------+--------------------+----+-----------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+--------------------+----+-----------+------------------+--------------------+-------------------+----------------+-----------------+--------+-----------+--------------------+----------------+----------------+-----------------+--------------------+\n",
      "|format|                  id|name|description|          location|           createdAt|       lastModified|partitionColumns|clusteringColumns|numFiles|sizeInBytes|          properties|minReaderVersion|minWriterVersion|    tableFeatures|          statistics|\n",
      "+------+--------------------+----+-----------+------------------+--------------------+-------------------+----------------+-----------------+--------+-----------+--------------------+----------------+----------------+-----------------+--------------------+\n",
      "| delta|505a9da5-3e4f-469...|NULL|       NULL|dbfs:/delta/orders|2024-09-17 04:41:...|2024-09-17 05:04:39|              []|               []|       1|       1594|{delta.enableDele...|               3|               7|[deletionVectors]|{numRowsDeletedBy...|\n",
      "+------+--------------------+----+-----------+------------------+--------------------+-------------------+----------------+-----------------+--------+-----------+--------------------+----------------+----------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the transaction history using PySpark\n",
    "delta_table.history().show()\n",
    "# Check file details using PySpark\n",
    "spark.sql(\"DESCRIBE DETAIL delta.`/delta/orders`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56e83bc9-65ef-4189-be31-0f44351e86fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th></tr></thead><tbody><tr><td>delta</td><td>505a9da5-3e4f-469c-ba9c-1974afaed544</td><td>null</td><td>null</td><td>dbfs:/delta/orders</td><td>2024-09-17T04:41:18.952Z</td><td>2024-09-17T05:04:39Z</td><td>List()</td><td>List()</td><td>1</td><td>1594</td><td>Map(delta.enableDeletionVectors -> true)</td><td>3</td><td>7</td><td>List(deletionVectors)</td><td>Map(numRowsDeletedByDeletionVectors -> 0, numDeletionVectors -> 0)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta",
         "505a9da5-3e4f-469c-ba9c-1974afaed544",
         null,
         null,
         "dbfs:/delta/orders",
         "2024-09-17T04:41:18.952Z",
         "2024-09-17T05:04:39Z",
         [],
         [],
         1,
         1594,
         {
          "delta.enableDeletionVectors": "true"
         },
         3,
         7,
         [
          "deletionVectors"
         ],
         {
          "numDeletionVectors": 0,
          "numRowsDeletedByDeletionVectors": 0
         }
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 97
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "format",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "createdAt",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "lastModified",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "partitionColumns",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "clusteringColumns",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sizeInBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "properties",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "minReaderVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minWriterVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tableFeatures",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "statistics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"long\",\"valueContainsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Check the transaction history using SQL\n",
    "DESCRIBE HISTORY delta.`/delta/orders`;\n",
    "-- Check file details using SQL\n",
    "DESCRIBE DETAIL delta.`/delta/orders`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b01e97d9-8511-47c1-8a32-d7d7e313b425",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85218661-8610-42ea-a9ec-2529c7d433ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-------+--------+-----+\n",
      "|OrderID| OrderDate|CustomerID|Product|Quantity|Price|\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "|    102|2024-01-02|      C002|  Phone|       1|  500|\n",
      "|    103|2024-01-03|      C003| Tablet|       3|  300|\n",
      "|    104|2024-01-04|      C004|Monitor|       1|  150|\n",
      "|    105|2024-01-05|      C005|  Mouse|       5|   20|\n",
      "|    101|2024-01-01|      C001| Laptop|       2| 1100|\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "|OrderID| OrderDate|CustomerID|Product|Quantity|Price|\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "|    101|2024-01-01|      C001| Laptop|       2| 1000|\n",
      "|    102|2024-01-02|      C002|  Phone|       1|  500|\n",
      "|    103|2024-01-03|      C003| Tablet|       3|  300|\n",
      "|    104|2024-01-04|      C004|Monitor|       1|  150|\n",
      "|    105|2024-01-05|      C005|  Mouse|       5|   20|\n",
      "+-------+----------+----------+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the table as it existed at a specific version\n",
    "df_version = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/delta/orders\")\n",
    "df_version.show()\n",
    "\n",
    "# Query the table as it existed at a specific timestamp\n",
    "df_timestamp = spark.read.format(\"delta\").option(\"timestampAsOf\", \"2024-09-17T04:41:20Z\").load(\"/delta/orders\")\n",
    "df_timestamp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "851ba18f-34c9-4aa9-ab14-7cff15fd774a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2145723-064d-45e1-96f2-fcd780dc7f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the table and Z-order by Product column\n",
    "spark.sql(\"OPTIMIZE delta.`/delta/orders` ZORDER BY (Product)\")\n",
    "# Vacuum the Delta table to remove old versions of the files\n",
    "spark.sql(\"VACUUM delta.`/delta/orders` RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ac0b052-3a2e-4f87-9a2f-b6864b044e2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d8a0d1d-0d24-4e2f-b34f-47c924245fec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+-------+--------+-----+\n",
      "|OrderID|OrderDate|CustomerID|Product|Quantity|Price|\n",
      "+-------+---------+----------+-------+--------+-----+\n",
      "+-------+---------+----------+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "\n",
    "# Define the schema of your Parquet file\n",
    "schema = StructType([\n",
    "    StructField(\"OrderID\", StringType(), True),\n",
    "    StructField(\"OrderDate\", DateType(), True),\n",
    "    StructField(\"CustomerID\", StringType(), True),\n",
    "    StructField(\"Product\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"Price\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "parquet_path = \"/dbfs/FileStore/\"\n",
    "delta_path = \"/dbfs/FileStore/delta_table\"\n",
    "\n",
    "# Read Parquet data with the defined schema\n",
    "df_parquet = spark.read.format(\"parquet\").schema(schema).load(parquet_path)\n",
    "\n",
    "# Write the data in Delta format\n",
    "df_parquet.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "\n",
    "# Register the Delta table\n",
    "spark.sql(f\"CREATE TABLE delta_table USING DELTA LOCATION '{delta_path}'\")\n",
    "\n",
    "# Query the newly converted Delta table\n",
    "df_converted = spark.sql(\"SELECT * FROM delta_table\")\n",
    "df_converted.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f15b9df-a24d-479d-a771-c3efe81a7dc7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating and Scheduling a Job on Databricks using Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "515ce7ab-44b9-49b5-bed6-fdc0749ba489",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-------+--------+------+-----------+\n",
      "|OrderID| OrderDate|CustomerID|Product|Quantity| Price|TotalAmount|\n",
      "+-------+----------+----------+-------+--------+------+-----------+\n",
      "|    101|2024-01-01|      C001| Laptop|       2|1000.0|     2000.0|\n",
      "|    103|2024-01-03|      C003| Tablet|       3| 300.0|      900.0|\n",
      "|    105|2024-01-05|      C005|  Mouse|       5|  20.0|      100.0|\n",
      "+-------+----------+----------+-------+--------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"OrderID\", StringType(), True),\n",
    "    StructField(\"OrderDate\", DateType(), True),\n",
    "    StructField(\"CustomerID\", StringType(), True),\n",
    "    StructField(\"Product\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"Price\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "csv_path = \"dbfs:/FileStore/streaming/input/orders.csv\"\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(csv_path)\n",
    "\n",
    "# Add TotalAmount column and filter rows\n",
    "df_transformed = df.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"Price\")) \\\n",
    "                    .filter(col(\"Quantity\") > 1)\n",
    "\n",
    "# Write the transformed data to a Delta table with schema evolution enabled\n",
    "delta_path = \"/dbfs/FileStore/delta_table\"\n",
    "df_transformed.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").save(delta_path)\n",
    "\n",
    "# Register the Delta table\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_table USING DELTA LOCATION '{delta_path}'\")\n",
    "\n",
    "# Query the Delta table to verify the transformation\n",
    "df_converted = spark.sql(\"SELECT * FROM delta_table\")\n",
    "df_converted.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 418182220691854,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Sep 17",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
