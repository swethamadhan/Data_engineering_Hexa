{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffb840dc-785e-4279-ba64-e0a4c4384ff9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Assignment 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc676ee9-84eb-45c7-b3b2-ca2ca88f6de8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/employee_data.csv\", \"dbfs:/FileStore/employee_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "741302cb-c566-482f-bbf4-05d7a51bd325",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1001|     John Doe|        HR| 2021-01-15| 55000|\n|      1002|   Jane Smith|        IT| 2020-03-10| 62000|\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1004|Michael Brown|        HR| 2018-12-22| 54000|\n|      1005| David Wilson|        IT| 2021-06-25| 58000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n|      1007| James Miller|        IT| 2019-08-14| 65000|\n|      1008|Barbara Moore|        HR| 2021-03-29| 53000|\n+----------+-------------+----------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Load the file from DBFS\n",
    "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/FileStore/employee_data.csv\")\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e15cb05f-a2a7-4b9d-b5c9-3b4876fbf5d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b93786b-989b-451b-95c3-ea064fee0e3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Load the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ad135b-52a5-4ea5-add1-62b9d8fe368f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1001|     John Doe|        HR| 2021-01-15| 55000|\n|      1002|   Jane Smith|        IT| 2020-03-10| 62000|\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1004|Michael Brown|        HR| 2018-12-22| 54000|\n|      1005| David Wilson|        IT| 2021-06-25| 58000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n|      1007| James Miller|        IT| 2019-08-14| 65000|\n|      1008|Barbara Moore|        HR| 2021-03-29| 53000|\n+----------+-------------+----------+-----------+------+\n\nroot\n |-- EmployeeID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- JoiningDate: date (nullable = true)\n |-- Salary: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Assuming the CSV file is in your Databricks workspace\n",
    "employee_df = spark.read.csv(\"/FileStore/employee_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the first 10 rows\n",
    "employee_df.show(10)\n",
    "\n",
    "# Inspect the schema\n",
    "employee_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1dd3273-2cbb-43b3-bfb6-53fc8e3988fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "352c2097-c09e-4eaa-9261-6ffb360d58d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows with Salary less than 55,000\n",
    "filtered_df = employee_df.filter(F.col(\"Salary\") >= 55000)\n",
    "\n",
    "# Filter employees who joined after 2020\n",
    "filtered_df = filtered_df.filter(F.year(F.col(\"JoiningDate\")) > 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "225422cc-f349-43ac-9e33-ebf2154e7dcf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f420874-5deb-4f15-ae88-7ce1d64b099f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Average salary by Department\n",
    "avg_salary_by_department = filtered_df.groupBy(\"Department\").agg(F.avg(\"Salary\").alias(\"AverageSalary\"))\n",
    "\n",
    "# Count of employees in each Department\n",
    "employee_count_by_department = filtered_df.groupBy(\"Department\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8e1450c-0456-4d30-992d-1a5046211a5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Write the Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b46a0532-abdc-4adb-bd8c-09f78200bf86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "filtered_df.write.csv(\"cleaned_employee_data.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c01fb988-70d6-44cc-a77c-c30f69115882",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Assignment 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "313e5317-aac4-4a14-b04e-73ac1b404a52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/product_data.json\", \"dbfs:/FileStore/product_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619bb524-55af-4ae7-90b1-8e619a5cc90d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the file from DBFS\n",
    "df_json = spark.read.format(\"json\").option(\"header\", \"true\").load(\"/FileStore/product_data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0d21a7f-7ea0-4d01-b693-3609a1e26ee3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Load the JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b8dba2-8255-4abb-befb-6028d6a9921f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics| 1200|      101|     Laptop|   35|\n|Electronics|  800|      102| Smartphone|   80|\n|  Furniture|  150|      103| Desk Chair|   60|\n|Electronics|  300|      104|    Monitor|   45|\n|  Furniture|  350|      105|       Desk|   25|\n+-----------+-----+---------+-----------+-----+\n\nroot\n |-- Category: string (nullable = true)\n |-- Price: long (nullable = true)\n |-- ProductID: long (nullable = true)\n |-- ProductName: string (nullable = true)\n |-- Stock: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load the file from DBFS\n",
    "df = spark.read.option(\"multiline\", \"true\").json(\"/FileStore/product_data.json\")\n",
    "df.show(10)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "067c32fd-d22d-4a89-860c-4cb44138ff15",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32482ff5-9cd0-42f9-938f-f822805a2ddd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics| 1200|      101|     Laptop|   35|\n|Electronics|  800|      102| Smartphone|   80|\n|Electronics|  300|      104|    Monitor|   45|\n+-----------+-----+---------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove rows where Stock is less than 30.\n",
    "# Filter the products that belong to the \"Electronics\" category.\n",
    "df_cleaned_product = df.filter((df['Stock'] >= 30) & (df['Category'] == 'Electronics'))\n",
    "df_cleaned_product.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "661ab3da-6f09-4a07-974f-cc5ce2dbd25f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f89107-67e3-4ef1-bea3-06c3f9687478",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n| Category|TotalStock|\n+---------+----------+\n|Furniture|        85|\n+---------+----------+\n\n+-----------+-----------------+\n|   Category|         AvgPrice|\n+-----------+-----------------+\n|Electronics|766.6666666666666|\n|  Furniture|            250.0|\n+-----------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the total stock for products in the \"Furniture\" category.\n",
    "df_total_furniture_stock = df.filter(df['Category'] == 'Furniture').groupBy('Category').agg({'Stock': 'sum'}).withColumnRenamed('sum(Stock)', 'TotalStock')\n",
    "df_total_furniture_stock.show()\n",
    "\n",
    "# Find the average price of all products in the dataset.\n",
    "df_avg_price = df.groupBy('Category').agg({'Price': 'avg'}).withColumnRenamed('avg(Price)', 'AvgPrice')\n",
    "df_avg_price.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff8ee990-26cb-48b1-8dcd-5d5c5c126bae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Write the Data to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a375d476-d725-4569-9716-608fa6923b71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the cleaned and aggregated data into a new JSON file.\n",
    "df_cleaned_product.coalesce(1).write.json('/FileStore/cleaned_product_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aae5e98c-2587-4671-8e53-9a31562095a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Assignment 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "444c644e-3e5a-4226-9497-ec9511068858",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Convert CSV and JSON Data to Delta Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd5923e-f5b7-4b01-b1ac-bfece15fa8e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1001|     John Doe|        HR| 2021-01-15| 55000|\n|      1002|   Jane Smith|        IT| 2020-03-10| 62000|\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1004|Michael Brown|        HR| 2018-12-22| 54000|\n|      1005| David Wilson|        IT| 2021-06-25| 58000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n|      1007| James Miller|        IT| 2019-08-14| 65000|\n|      1008|Barbara Moore|        HR| 2021-03-29| 53000|\n+----------+-------------+----------+-----------+------+\n\nroot\n |-- EmployeeID: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- JoiningDate: date (nullable = true)\n |-- Salary: integer (nullable = true)\n\n+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics| 1200|      101|     Laptop|   35|\n|Electronics|  800|      102| Smartphone|   80|\n|  Furniture|  150|      103| Desk Chair|   60|\n|Electronics|  300|      104|    Monitor|   45|\n|  Furniture|  350|      105|       Desk|   25|\n+-----------+-----+---------+-----------+-----+\n\nroot\n |-- Category: string (nullable = true)\n |-- Price: long (nullable = true)\n |-- ProductID: long (nullable = true)\n |-- ProductName: string (nullable = true)\n |-- Stock: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load employee.csv file data\n",
    "df_employee = spark.read.csv('/FileStore/employee_data.csv', header=True, inferSchema=True).cache()\n",
    "df_employee.show()\n",
    "df_employee.printSchema()\n",
    "\n",
    "# Load product_data.json file\n",
    "df = spark.read.option(\"multiline\", \"true\").json(\"/FileStore/product_data.json\")\n",
    "df.show(10)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f32d3dd-8f3c-4b36-8d92-212443b77d7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_employee.write.format(\"delta\").mode(\"overwrite\").save(\"/dbfs/FileStore/delta/employee_data\")\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/dbfs/FileStore/delta/product_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5789f5c-3fb5-426b-b587-a5123166c28e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2. Register Delta Tables as SQL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b8e3f9-b54a-4747-8699-e049853cd0da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS employee_delta USING DELTA LOCATION '/dbfs/FileStore/delta/employee_data'\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS product_delta USING DELTA LOCATION '/dbfs/FileStore/delta/product_data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d3af177-5c73-47a2-a7ff-74955a8476f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "3. Data Modifications with Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934d717c-844c-4e85-bec2-bac6bda9422e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Increase salary by 5% for IT department employees\n",
    "spark.sql(\"UPDATE employee_delta SET Salary = Salary * 1.05 WHERE Department = 'IT'\")\n",
    "# Delete products where stock is less than 40\n",
    "spark.sql(\"DELETE FROM product_delta WHERE Stock < 40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee410b6f-19b9-480b-a225-5d1ac25f3dd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4. Time Travel with Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "520c89b2-efe7-4bd5-9f9e-0c674f18e0dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics| 1200|      101|     Laptop|   35|\n|Electronics|  800|      102| Smartphone|   80|\n|  Furniture|  150|      103| Desk Chair|   60|\n|Electronics|  300|      104|    Monitor|   45|\n|  Furniture|  350|      105|       Desk|   25|\n+-----------+-----+---------+-----------+-----+\n\n+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1001|     John Doe|        HR| 2021-01-15| 55000|\n|      1002|   Jane Smith|        IT| 2020-03-10| 62000|\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1004|Michael Brown|        HR| 2018-12-22| 54000|\n|      1005| David Wilson|        IT| 2021-06-25| 58000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n|      1007| James Miller|        IT| 2019-08-14| 65000|\n|      1008|Barbara Moore|        HR| 2021-03-29| 53000|\n+----------+-------------+----------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Query the product Delta table to show its state before the delete\n",
    "# operation (use time travel).\n",
    "df_product_version_before_delete = spark.sql(\"SELECT * FROM product_delta VERSION AS OF 0\")\n",
    "df_product_version_before_delete.show()\n",
    "# Retrieve the version of the employee Delta table before the salary update.\n",
    "df_employee_version_before_update = spark.sql(\"SELECT * FROM employee_delta VERSION AS OF 0\")\n",
    "df_employee_version_before_update.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01ff82b3-4e6b-4ab3-a4c8-50be98d02112",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "5. Query Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff84a7a6-c4d9-49e5-a581-84bf835b8c02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n+----------+-------------+----------+-----------+------+\n\n+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics|  800|      102| Smartphone|   80|\n+-----------+-----+---------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Query the employee Delta table to find the employees in the Finance department.\n",
    "df_finance_employees = spark.sql(\"SELECT * FROM employee_delta WHERE Department = 'Finance'\")\n",
    "df_finance_employees.show()\n",
    "# Query the product Delta table to find all products in the Electronics category with a price greater than 500.\n",
    "df_expensive_electronics = spark.sql(\"SELECT * FROM product_delta WHERE Category = 'Electronics' AND Price > 500\")\n",
    "df_expensive_electronics.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks_Task2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
