{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d1df42-cf5e-4daf-915e-07b96090f4c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Move the file from Workspace to DBFS\n",
    "\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/employee_updates.csv\", \"dbfs:/FileStore/employee_updates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "665df1eb-7e08-4ebf-9c15-a64246500c05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Convert employee CSV data to Delta format\n",
    "df_employee = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/FileStore/employee_data.csv\")\n",
    "\n",
    "df_employee.write.format(\"delta\").mode (\"overwrite\").save(\"/delta/employee_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5411dc3e-6123-4188-acc1-7df1c8ce1c74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert employee updates CSV data to Delta format\n",
    "df_employee_updates = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/FileStore/employee_updates.csv\")\n",
    "\n",
    "df_employee_updates.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/employee_updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca3c303-22c4-471b-b108-79f06ff29473",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load Delta tables\n",
    "df_employee = spark.read.format(\"delta\").load(\"/delta/employee_data\")\n",
    "df_employee_updates = spark.read.format(\"delta\").load(\"/delta/employee_updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14bb713c-cf51-4c7a-b217-7ab8f0f97355",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create temporary views for SQL operations with corrected view names\n",
    "df_employee.createOrReplaceTempView(\"delta_employee\") \n",
    "\n",
    "df_employee_updates.createOrReplaceTempView(\"employee_updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0350a4a9-3d31-4ad9-8088-e230758f5ac8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CELL 4 ####\n",
    "spark.sql(\"\"\"\n",
    "    MERGE INTO delta_employee AS target\n",
    "    USING employee_updates AS source\n",
    "    ON target.EmployeeID = source.EmployeeID\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        target.Salary = source.Salary,\n",
    "        target.Department = source.Department\n",
    "    WHEN NOT MATCHED THEN INSERT \n",
    "    (\n",
    "        EmployeeID, Name, Department, JoiningDate, Salary\n",
    "    ) VALUES (\n",
    "        source.EmployeeID, source.Name, source.Department, source.JoiningDate, source.Salary\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4517a04-8700-450f-974f-3a39cf58f834",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+-----------+------+\n",
      "|EmployeeID|         Name|Department|JoiningDate|Salary|\n",
      "+----------+-------------+----------+-----------+------+\n",
      "|      1002|   Jane Smith|        IT| 2020-03-10| 62000|\n",
      "|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n",
      "|      1004|Michael Brown|        HR| 2018-12-22| 54000|\n",
      "|      1005| David Wilson|        IT| 2021-06-25| 58000|\n",
      "|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n",
      "|      1007| James Miller|        IT| 2019-08-14| 65000|\n",
      "|      1008|Barbara Moore|        HR| 2021-03-29| 53000|\n",
      "|      1001|     John Doe|        HR| 2021-01-15| 58000|\n",
      "|      1009|  Sarah Adams| Marketing| 2021-09-01| 60000|\n",
      "|      1010|  Robert King|        IT| 2022-01-10| 62000|\n",
      "+----------+-------------+----------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query the Delta table to check if the data was updated or inserted correctly \n",
    "spark.sql(\"SELECT * FROM delta_employee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eaae41e-5689-40c1-8d1c-f16c3ba25d9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the employee DataFrame to a Delta Table\n",
    "\n",
    "df_employee.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/employee_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245d94e2-cec8-4d84-a187-7b5e20a7b934",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the Delta Table\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS delta_employee_table USING DELTA LOCATION '/delta/employee_data'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e694cc59-bf81-4874-b5d8-de6a185c365b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numClusteringTasksPlanned:int,numCompactionTasksPlanned:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numIntermediateNodesCompacted:bigint,totalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimize the Delta Table\n",
    "spark.sql(\"OPTIMIZE delta_employee_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b4723f9-594e-4897-8479-9638c749c5c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+----------------------------------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n",
      "|version|timestamp          |userId          |userName                          |operation|operationParameters                                                                                                                                                                                                |job |notebook          |clusterId           |readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |userMetadata|engineInfo                                |\n",
      "+-------+-------------------+----------------+----------------------------------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n",
      "|10     |2024-09-13 04:19:14|4164096982719713|azuser2140_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                       |NULL|{1592661905221818}|0911-085840-w2xap01c|9          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 10, numOutputBytes -> 1662}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|9      |2024-09-13 04:17:26|4164096982719713|azuser2140_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}                                                                                                                                     |NULL|{1592661905221818}|0911-085840-w2xap01c|8          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 2899, p25FileSize -> 1662, numDeletionVectorsRemoved -> 1, minFileSize -> 1662, numAddedFiles -> 1, maxFileSize -> 1662, p75FileSize -> 1662, p50FileSize -> 1662, numAddedBytes -> 1662}                                                                                                                                                                                                                                                                                                                                                                                                                                                   |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|8      |2024-09-13 04:17:22|4164096982719713|azuser2140_mml.local@techademy.com|MERGE    |{predicate -> [\"(EmployeeID#789 = EmployeeID#799)\"], matchedPredicates -> [{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}]}  |NULL|{1592661905221818}|0911-085840-w2xap01c|7          |WriteSerializable|false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1342, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 1, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 6109, materializeSourceTimeMs -> 1025, numTargetRowsInserted -> 2, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 2786, numTargetRowsUpdated -> 1, numOutputRows -> 3, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 2173}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|7      |2024-09-13 04:16:47|4164096982719713|azuser2140_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                       |NULL|{1592661905221818}|0911-085840-w2xap01c|6          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 8, numOutputBytes -> 1557}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|6      |2024-09-12 12:01:06|4164096982719713|azuser2140_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}                                                                                                                                     |NULL|{1592661905221818}|0911-085840-w2xap01c|5          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 3004, p25FileSize -> 1662, numDeletionVectorsRemoved -> 1, minFileSize -> 1662, numAddedFiles -> 1, maxFileSize -> 1662, p75FileSize -> 1662, p50FileSize -> 1662, numAddedBytes -> 1662}                                                                                                                                                                                                                                                                                                                                                                                                                                                   |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|5      |2024-09-12 12:01:03|4164096982719713|azuser2140_mml.local@techademy.com|MERGE    |{predicate -> [\"(EmployeeID#2035 = EmployeeID#2045)\"], matchedPredicates -> [{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}]}|NULL|{1592661905221818}|0911-085840-w2xap01c|4          |WriteSerializable|false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1342, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 1, numTargetRowsMatchedUpdated -> 3, executionTimeMs -> 2633, materializeSourceTimeMs -> 203, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 1130, numTargetRowsUpdated -> 3, numOutputRows -> 3, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 1260} |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|4      |2024-09-12 11:54:37|4164096982719713|azuser2140_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}                                                                                                                                     |NULL|{1592661905221818}|0911-085840-w2xap01c|3          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 2899, p25FileSize -> 1662, numDeletionVectorsRemoved -> 1, minFileSize -> 1662, numAddedFiles -> 1, maxFileSize -> 1662, p75FileSize -> 1662, p50FileSize -> 1662, numAddedBytes -> 1662}                                                                                                                                                                                                                                                                                                                                                                                                                                                   |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|3      |2024-09-12 11:54:32|4164096982719713|azuser2140_mml.local@techademy.com|MERGE    |{predicate -> [\"(EmployeeID#2035 = EmployeeID#2045)\"], matchedPredicates -> [{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}]}|NULL|{1592661905221818}|0911-085840-w2xap01c|2          |WriteSerializable|false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1342, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 1, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 5946, materializeSourceTimeMs -> 870, numTargetRowsInserted -> 2, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 2912, numTargetRowsUpdated -> 1, numOutputRows -> 3, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 2062} |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|2      |2024-09-12 11:49:04|4164096982719713|azuser2140_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                       |NULL|{1592661905221818}|0911-085840-w2xap01c|1          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 8, numOutputBytes -> 1557}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|1      |2024-09-12 10:10:46|4164096982719713|azuser2140_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                       |NULL|{301304717901183} |0911-085840-w2xap01c|0          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 8, numOutputBytes -> 1557}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "|0      |2024-09-12 10:02:33|4164096982719713|azuser2140_mml.local@techademy.com|WRITE    |{mode -> ErrorIfExists, statsOnLoad -> false, partitionBy -> []}                                                                                                                                                   |NULL|{301304717901183} |0911-085840-w2xap01c|NULL       |WriteSerializable|true         |{numFiles -> 1, numOutputRows -> 8, numOutputBytes -> 1557}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n",
      "+-------+-------------------+----------------+----------------------------------+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#describe the history of the delta table\n",
    "spark.sql(\"DESCRIBE HISTORY delta_employee_table\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d440c15-f705-427d-a2f4-5a6a7908d474",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create table unmanaged_data(\n",
    "  id INT,\n",
    "  nmae STRING\n",
    ")\n",
    "location '/user/data/external_data/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "create table managed_data(\n",
    "  id INT,\n",
    "  nmae STRING\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Merging_of_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
