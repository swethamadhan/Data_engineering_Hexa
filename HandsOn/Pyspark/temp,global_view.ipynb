{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnOFbEAcUqMn",
        "outputId": "1ec9bfa6-3d3d-405d-d267-2e07d948aee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=dbcd08a3b6abd940b09f05efe2c10c7e53499d0e912a0d5cc4ac64df3e80f56d\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"DataIngestion\") \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "BlakNBPKUufD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "upload csv and json files\n"
      ],
      "metadata": {
        "id": "6D83q37lnKI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/sample_data/people.csv\"\n",
        "\n",
        "# Now you can read it with PySpark\n",
        "\n",
        "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
        "df_csv.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd6Y4TOEWr8v",
        "outputId": "fd99f4e0-58c6-4299-d419-0a637d0bd379"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+-------+\n",
            "|Name| Age| Gender|\n",
            "+----+----+-------+\n",
            "|John|  28|   Male|\n",
            "|Jane|  32| Female|\n",
            "+----+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "# Define the schema for the JSON file\n",
        "schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"gender\", StringType(), True),\n",
        "    StructField(\"address\", StructType([\n",
        "        StructField(\"street\", StringType(), True),\n",
        "        StructField(\"city\", StringType(), True)\n",
        "    ]), True)\n",
        "])\n",
        "\n",
        "\n",
        "# load the complex json file with the correct path\n",
        "json_file_path = \"/content/sample_data/sample.json\"\n",
        "\n",
        "df_json_complex = spark.read.schema(schema).json(json_file_path)\n",
        "\n",
        "with open(json_file_path, \"r\") as f:\n",
        "  data = f.read()\n",
        "  print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWD-Sjo1h55l",
        "outputId": "d35565f8-85c8-42a0-92a6-5f5fc25e9d2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"name\": \"John\",\n",
            "    \"age\": 28,\n",
            "    \"gender\": \"Male\",\n",
            "    \"address\": {\n",
            "      \"street\": \"123 Main St\",\n",
            "      \"city\": \"New York\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Jane\",\n",
            "    \"age\": 32,\n",
            "    \"gender\": \"Female\",\n",
            "    \"address\": {\n",
            "      \"street\": \"456 Elm St\",\n",
            "      \"city\": \"San Francisco\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temp View and Global Temp View\n",
        ""
      ],
      "metadata": {
        "id": "ZNGp0NgbnICR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    \"name\": [\"John\", \"Jane\", \"Mike\", \"Emily\"],\n",
        "    \"age\": [28, 32, 45, 23],\n",
        "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\"],\n",
        "    \"city\": [\"New York\", \"San Francisco\", \"Los Angeles\", \"Chicago\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "csv_file_path = \"/content/sample_people.csv\"\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(\"csv file is created \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZw26ZQfmrfi",
        "outputId": "09284f9e-db3a-41d4-927a-f36e9c024fe6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file is created \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CreateViewExample\").getOrCreate()\n",
        "df_people = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(csv_file_path)\n",
        "df_people.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZDk5Wn3mr_n",
        "outputId": "33d5091b-1725-4b8b-d385-dfa856d54370"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+------+-------------+\n",
            "| name|age|gender|         city|\n",
            "+-----+---+------+-------------+\n",
            "| John| 28|  Male|     New York|\n",
            "| Jane| 32|Female|San Francisco|\n",
            "| Mike| 45|  Male|  Los Angeles|\n",
            "|Emily| 23|Female|      Chicago|\n",
            "+-----+---+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_people.createOrReplaceTempView(\"people_temp_view\")"
      ],
      "metadata": {
        "id": "vnCu1H2wmvUv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run an sql query on the view\n",
        "result_temp_view = spark.sql(\"SELECT name, age, gender, city FROM people_temp_view WHERE age > 30\")\n",
        "result_temp_view.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DirDLH3xm1O6",
        "outputId": "3204bc8c-45ea-4b87-b3e2-288bb77b7a9d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+------+-------------+\n",
            "|name|age|gender|         city|\n",
            "+----+---+------+-------------+\n",
            "|Jane| 32|Female|San Francisco|\n",
            "|Mike| 45|  Male|  Los Angeles|\n",
            "+----+---+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_people.createOrReplaceGlobalTempView(\"people_global_view\")\n",
        "result_global_view = spark.sql(\"SELECT name, age, city FROM global_temp.people_global_view WHERE age < 30\")\n",
        "result_global_view.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO2OJdWXm3Ha",
        "outputId": "e6b1b9d5-d4a2-4552-d86e-718b8e596989"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------+\n",
            "| name|age|    city|\n",
            "+-----+---+--------+\n",
            "| John| 28|New York|\n",
            "|Emily| 23| Chicago|\n",
            "+-----+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.listTables()\n",
        "\n",
        "spark.catalog.dropTempView(\"people_temp_view\")\n",
        "spark.catalog.dropGlobalTempView(\"people_global_view\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AXAwxdwm5JO",
        "outputId": "dd39c055-cc41-4521-b85d-df52e05c1f78"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8gOM4BIm7Nx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}