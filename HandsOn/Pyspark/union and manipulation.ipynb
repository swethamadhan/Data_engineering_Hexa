{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qCVVV-F52mgGdJGjbP0HR8nlG-2IAplf","timestamp":1725434429865}],"authorship_tag":"ABX9TyONWqhrsTbiWamgOFucMqM6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKbkMO0r3Ypf","executionInfo":{"status":"ok","timestamp":1725439411346,"user_tz":-330,"elapsed":60026,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"594208ae-4c29-49c3-ae3c-a2c867e55cac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=6ebaced058603b893a9d92c9e59ab5b76d67b8d631405678216e6746564bf0e7\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}],"source":["! pip install pyspark"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","\n","# Initialize a Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"Advanced DataFrame Operations\") \\\n","    .getOrCreate()\n","\n","# Create two sample DataFrames\n","data1 = [\n","    (1, 'Arjun', 'IT', 75000, '2022-01-15'),\n","    (2, 'Vijay', 'Finance', 85000, '2022-03-12'),\n","    (3, 'Shalini', 'IT', 90000, '2021-06-30')\n","]\n","\n","data2 = [\n","    (4, 'Sneha', 'HR', 50000, '2022-05-01'),\n","    (5, 'Rahul', 'Finance', 60000, '2022-08-20'),\n","    (6, 'Amit', 'IT', 55000, '2021-12-15')\n","]\n","\n","# Define schema (columns)\n","columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary', 'JoiningDate']\n","\n","# Create DataFrames\n","employee_df1 = spark.createDataFrame(data1, columns)\n","employee_df2 = spark.createDataFrame(data2, columns)\n","\n","# Show the DataFrames\n","print(\"Employee DataFrame 1:\")\n","employee_df1.show()\n","\n","print(\"Employee DataFrame 2:\")\n","employee_df2.show()\n","\n"],"metadata":{"id":"0pISgyKv3mxq","executionInfo":{"status":"ok","timestamp":1725440511782,"user_tz":-330,"elapsed":22827,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47f6c76c-bc63-48e0-8503-a00ac6e7a615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Employee DataFrame 1:\n","+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|\n","+----------+------------+----------+------+-----------+\n","\n","Employee DataFrame 2:\n","+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         4|       Sneha|        HR| 50000| 2022-05-01|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|\n","|         6|        Amit|        IT| 55000| 2021-12-15|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["# Union of two DataFrames (removes duplicates)\n","union_df = employee_df1.union(employee_df2).dropDuplicates()\n","union_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XH0l2tXhRJoI","executionInfo":{"status":"ok","timestamp":1725440564825,"user_tz":-330,"elapsed":3198,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"0c5acc99-76a6-40e6-8f7d-7ba13597927c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|\n","|         6|        Amit|        IT| 55000| 2021-12-15|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["# Union of two DataFrames (includes duplicates)\n","union_all_df = employee_df1.union(employee_df2)\n","union_all_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WgJqF8HRZZJ","executionInfo":{"status":"ok","timestamp":1725440582017,"user_tz":-330,"elapsed":1670,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"41cf3934-a321-49da-d230-c3d1b882aa2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|\n","|         6|        Amit|        IT| 55000| 2021-12-15|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.window import Window\n","from pyspark.sql.functions import rank\n","from pyspark.sql.functions import col\n","\n","# Define a window specification to rank employees by salary within each department\n","window_spec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n","\n","# Add a rank column to the DataFrame\n","ranked_df = union_all_df.withColumn(\"Rank\", rank().over(window_spec))\n","ranked_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pf_T7NljRf7_","executionInfo":{"status":"ok","timestamp":1725440880262,"user_tz":-330,"elapsed":2096,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"fc2680ff-7fa3-40ee-b91f-4fef534f7039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+----+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|Rank|\n","+----------+------------+----------+------+-----------+----+\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|   1|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|   2|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|   1|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|   1|\n","|         1|       Arjun|        IT| 75000| 2022-01-15|   2|\n","|         6|        Amit|        IT| 55000| 2021-12-15|   3|\n","+----------+------------+----------+------+-----------+----+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import sum\n","\n","# Define a window specification for cumulative sum of salaries within each department\n","window_spec_sum = Window.partitionBy(\"Department\").orderBy(\"JoiningDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n","\n","# Calculate the running total of salaries\n","running_total_df = union_all_df.withColumn(\"RunningTotal\", sum(col(\"Salary\")).over(window_spec_sum))\n","running_total_df.show()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8IzxKUlSpNA","executionInfo":{"status":"ok","timestamp":1725441165993,"user_tz":-330,"elapsed":1636,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"1b0db2ee-8417-4d8e-f377-d3941ce21415"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|RunningTotal|\n","+----------+------------+----------+------+-----------+------------+\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|       85000|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|      145000|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|       50000|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|       90000|\n","|         6|        Amit|        IT| 55000| 2021-12-15|      145000|\n","|         1|       Arjun|        IT| 75000| 2022-01-15|      220000|\n","+----------+------------+----------+------+-----------+------------+\n","\n"]}]},{"cell_type":"code","source":["# Convert JoiningDate from string to date type\n","date_converted_df = union_all_df.withColumn(\"JoiningDate\", F.to_date(col(\"JoiningDate\"), \"yyyy-MM-dd\"))\n","date_converted_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"om9om4oaTu61","executionInfo":{"status":"ok","timestamp":1725441233762,"user_tz":-330,"elapsed":1644,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"1e8a87e2-1e82-44b8-b3b0-7cf482784ac5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|\n","|         6|        Amit|        IT| 55000| 2021-12-15|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["# Calculate the number of years since joining\n","experience_df = date_converted_df.withColumn(\"YearsOfExperience\", F.round(F.datediff(F.current_date(), col(\"JoiningDate\")) / 365, 2))\n","experience_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crPH7laPT-aO","executionInfo":{"status":"ok","timestamp":1725441292917,"user_tz":-330,"elapsed":1622,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"a5e41b63-75ca-4bd3-bb8f-b3ace74521cd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+-----------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|YearsOfExperience|\n","+----------+------------+----------+------+-----------+-----------------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|             2.64|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|             2.48|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|             3.18|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|             2.35|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|             2.04|\n","|         6|        Amit|        IT| 55000| 2021-12-15|             2.72|\n","+----------+------------+----------+------+-----------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["# Add a new column for next evaluation date (one year after joining)\n","eval_date_df = date_converted_df.withColumn(\"NextEvaluationDate\", F.date_add(col(\"JoiningDate\"), 365))\n","eval_date_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1TqFAic5UQV0","executionInfo":{"status":"ok","timestamp":1725441355487,"user_tz":-330,"elapsed":1499,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"0591e0f5-81d6-4119-8912-35d382736dad"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+------------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|NextEvaluationDate|\n","+----------+------------+----------+------+-----------+------------------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|        2023-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|        2023-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|        2022-06-30|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|        2023-05-01|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|        2023-08-20|\n","|         6|        Amit|        IT| 55000| 2021-12-15|        2022-12-15|\n","+----------+------------+----------+------+-----------+------------------+\n","\n"]}]},{"cell_type":"code","source":["# Calculate average salary per department\n","avg_salary_df = union_all_df.groupBy(\"Department\").agg(F.avg(col(\"Salary\")).alias(\"AverageSalary\"))\n","avg_salary_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W02mGKkqUbjZ","executionInfo":{"status":"ok","timestamp":1725441385789,"user_tz":-330,"elapsed":1790,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"55848389-115e-4afb-b09d-3fc21f9c86bc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-----------------+\n","|Department|    AverageSalary|\n","+----------+-----------------+\n","|        IT|73333.33333333333|\n","|   Finance|          72500.0|\n","|        HR|          50000.0|\n","+----------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["# Calculate the total number of employees\n","total_employees_df = union_all_df.agg(F.count(\"EmployeeID\").alias(\"TotalEmployees\"))\n","total_employees_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtS7XVa1Ui1G","executionInfo":{"status":"ok","timestamp":1725441427368,"user_tz":-330,"elapsed":1584,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"88db961b-2546-44d7-d37a-8c9e779950d0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------+\n","|TotalEmployees|\n","+--------------+\n","|             6|\n","+--------------+\n","\n"]}]},{"cell_type":"code","source":["# Convert EmployeeNAme to upper case\n","Upper_name_df = union_all_df.withColumn(\"EmployeeNameUpper\", F.upper(col(\"EmployeeNAme\")))\n","Upper_name_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KI6AUfNxUtrr","executionInfo":{"status":"ok","timestamp":1725441577854,"user_tz":-330,"elapsed":1549,"user":{"displayName":"Swetha .R","userId":"11283228655930516066"}},"outputId":"9a45af89-c668-42a3-fd58-ed9f2397c09a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+-----------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|EmployeeNameUpper|\n","+----------+------------+----------+------+-----------+-----------------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|            ARJUN|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|            VIJAY|\n","|         3|     Shalini|        IT| 90000| 2021-06-30|          SHALINI|\n","|         4|       Sneha|        HR| 50000| 2022-05-01|            SNEHA|\n","|         5|       Rahul|   Finance| 60000| 2022-08-20|            RAHUL|\n","|         6|        Amit|        IT| 55000| 2021-12-15|             AMIT|\n","+----------+------------+----------+------+-----------+-----------------+\n","\n"]}]}]}